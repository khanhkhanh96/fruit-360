{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "b6Sjd4PLxFU3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "826c45e6-c08a-4697-c157-20e5b2c43385",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529724807830,
          "user_tz": -420,
          "elapsed": 13404,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!wget https://uaelxg.bn.files.1drv.com/y4mfVVREWQ1x_HQo_XjcLkz4Ae0EAdMbms2x6o5FQfnwhCpvZmgYAZsRA0A8UIeISKnECDolIAbdclP-YkAN12KLPImrtIQ4vbJquc_Joty_5Ouvb5gNZ1HY5vhnb-EaXl3P7sBVZk8j_-L3QhGHiPhUXEYAyGoMf0s3TnYYKh_hIxL-oz_hFShHbBrNUJu2yLQ/fruits-360_dataset_2018_06_03.zip\n",
        "  \n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-23 03:33:04--  https://uaelxg.bn.files.1drv.com/y4mfVVREWQ1x_HQo_XjcLkz4Ae0EAdMbms2x6o5FQfnwhCpvZmgYAZsRA0A8UIeISKnECDolIAbdclP-YkAN12KLPImrtIQ4vbJquc_Joty_5Ouvb5gNZ1HY5vhnb-EaXl3P7sBVZk8j_-L3QhGHiPhUXEYAyGoMf0s3TnYYKh_hIxL-oz_hFShHbBrNUJu2yLQ/fruits-360_dataset_2018_06_03.zip\n",
            "Resolving uaelxg.bn.files.1drv.com (uaelxg.bn.files.1drv.com)... 204.79.197.213\n",
            "Connecting to uaelxg.bn.files.1drv.com (uaelxg.bn.files.1drv.com)|204.79.197.213|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211922343 (202M) [application/zip]\n",
            "Saving to: ‘fruits-360_dataset_2018_06_03.zip’\n",
            "\n",
            "fruits-360_dataset_ 100%[===================>] 202.10M  21.1MB/s    in 10s     \n",
            "\n",
            "2018-06-23 03:33:15 (19.7 MB/s) - ‘fruits-360_dataset_2018_06_03.zip’ saved [211922343/211922343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EoA4avPyxZLF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile('fruits-360_dataset_2018_06_03.zip', 'r')\n",
        "# zip_ref.extractall('data2')\n",
        "# zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "toPsKITGcSgp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc291508-cba6-4191-f9d0-dd0c4f06f69c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529673759667,
          "user_tz": -420,
          "elapsed": 1731,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data2  datalab\tfruits-360_dataset_2018_06_03.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "80p2ZdIyxnPM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85a22343-b125-4ff2-cef9-85437ebf1883",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529730799811,
          "user_tz": -420,
          "elapsed": 3178,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d5LLF14rqYhJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Load dữ liệu tập train và test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aI_1fwg3xoRe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "training_fruit_img = []\n",
        "training_label = []\n",
        "for dir_path in glob.glob(\"data2/fruits-360/Training/*\"):\n",
        "    img_label = dir_path.split(\"/\")[-1]\n",
        "    for image_path in glob.glob(os.path.join(dir_path,\"*.jpg\")):\n",
        "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
        "        image = cv2.resize(image, (64, 64))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        training_fruit_img.append(image)\n",
        "        training_label.append(img_label)\n",
        "training_fruit_img = np.array(training_fruit_img)\n",
        "training_label = np.array(training_label)\n",
        "label_to_id = {v:k for k,v in enumerate(np.unique(training_label)) }\n",
        "id_to_label = {v:k for k,v in label_to_id.items()}\n",
        "training_label_id = np.array([label_to_id[i] for i in training_label]) # chuyển trainlabel từ tên trái cây thành chỉ số từ 0->64\n",
        "validation_fruit_img=[]\n",
        "validation_label =[]\n",
        "for dir_path in glob.glob(\"data2/fruits-360/Validation/*\"):\n",
        "    img_label = dir_path.split(\"/\")[-1]\n",
        "    for image_path in glob.glob(os.path.join(dir_path,\"*.jpg\")):\n",
        "        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
        "        image = cv2.resize(image, (64, 64))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        validation_fruit_img.append(image)\n",
        "        validation_label.append(img_label)\n",
        "validation_fruit_img = np.array(validation_fruit_img)\n",
        "validation_label = np.array(validation_label)\n",
        "validation_label_id = np.array([label_to_id[i] for i in validation_label]) # chuyển validationlabel từ tên trái cây thành chỉ số từ 0->64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5UkIc_mxryR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2658
        },
        "outputId": "6269b19e-7641-426f-9c49-cf9ad1885bd6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529738208516,
          "user_tz": -420,
          "elapsed": 1122431,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#tạo cnn model\n",
        "\n",
        "batch_size = 80\n",
        "num_classes = 65\n",
        "epochs = 40\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 64, 64\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "\n",
        "\n",
        "y_train = training_label_id\n",
        "y_test = validation_label_id\n",
        "\n",
        "x_train = training_fruit_img.astype('float32')\n",
        "x_test = validation_fruit_img.astype('float32')\n",
        "\n",
        "# chuyển các giá trị dữ liệu hình ảnh thành 0->1\n",
        "x_test /= 255\n",
        "x_train /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "#tạo checkpoint để lưu lại model tại epoch có giá trị val_acc cao nhất\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_acc', verbose=0, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max', period=1)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size= (3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, kernel_size= (3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, kernel_size = (3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer = keras.optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=1,\n",
        "        validation_data=(x_test, y_test),\n",
        "         callbacks = [checkpoint])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "classes = model.predict_classes(x_test, batch_size = None)\n",
        "print(classification_report(validation_label_id, classes))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (32426, 64, 64, 3)\n",
            "32426 train samples\n",
            "10903 test samples\n",
            "Train on 32426 samples, validate on 10903 samples\n",
            "Epoch 1/40\n",
            "32426/32426 [==============================] - 29s 888us/step - loss: 0.9091 - acc: 0.7460 - val_loss: 0.3203 - val_acc: 0.8937\n",
            "Epoch 2/40\n",
            " 2480/32426 [=>............................] - ETA: 22s - loss: 0.1736 - acc: 0.9419"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 858us/step - loss: 0.1074 - acc: 0.9662 - val_loss: 0.1874 - val_acc: 0.9469\n",
            "Epoch 3/40\n",
            "24480/32426 [=====================>........] - ETA: 6s - loss: 0.0601 - acc: 0.9801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 858us/step - loss: 0.0571 - acc: 0.9810 - val_loss: 0.2024 - val_acc: 0.9428\n",
            "Epoch 4/40\n",
            "32426/32426 [==============================] - 28s 854us/step - loss: 0.0377 - acc: 0.9860 - val_loss: 0.1731 - val_acc: 0.9529\n",
            "Epoch 5/40\n",
            "  240/32426 [..............................] - ETA: 24s - loss: 0.0065 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 859us/step - loss: 0.0324 - acc: 0.9883 - val_loss: 0.1776 - val_acc: 0.9575\n",
            "Epoch 6/40\n",
            "23680/32426 [====================>.........] - ETA: 6s - loss: 0.0248 - acc: 0.9891"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 853us/step - loss: 0.0241 - acc: 0.9897 - val_loss: 0.1863 - val_acc: 0.9589\n",
            "Epoch 7/40\n",
            "32426/32426 [==============================] - 28s 855us/step - loss: 0.0261 - acc: 0.9899 - val_loss: 0.1763 - val_acc: 0.9590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/40\n",
            "32426/32426 [==============================] - 28s 854us/step - loss: 0.0226 - acc: 0.9907 - val_loss: 0.1418 - val_acc: 0.9629\n",
            "Epoch 9/40\n",
            "20960/32426 [==================>...........] - ETA: 8s - loss: 0.0223 - acc: 0.9904"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 852us/step - loss: 0.0226 - acc: 0.9904 - val_loss: 0.1928 - val_acc: 0.9566\n",
            "Epoch 10/40\n",
            "31440/32426 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9907"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 854us/step - loss: 0.0191 - acc: 0.9907 - val_loss: 0.1455 - val_acc: 0.9630\n",
            "Epoch 11/40\n",
            "32426/32426 [==============================] - 28s 854us/step - loss: 0.0178 - acc: 0.9915 - val_loss: 0.1691 - val_acc: 0.9608\n",
            "Epoch 12/40\n",
            " 1680/32426 [>.............................] - ETA: 24s - loss: 0.0112 - acc: 0.9940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 857us/step - loss: 0.0173 - acc: 0.9917 - val_loss: 0.1873 - val_acc: 0.9585\n",
            "Epoch 13/40\n",
            "24080/32426 [=====================>........] - ETA: 6s - loss: 0.0172 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 857us/step - loss: 0.0180 - acc: 0.9924 - val_loss: 0.1618 - val_acc: 0.9627\n",
            "Epoch 14/40\n",
            "32426/32426 [==============================] - 28s 851us/step - loss: 0.0189 - acc: 0.9916 - val_loss: 0.1127 - val_acc: 0.9709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/40\n",
            "32426/32426 [==============================] - 28s 854us/step - loss: 0.0159 - acc: 0.9909 - val_loss: 0.1793 - val_acc: 0.9607\n",
            "Epoch 16/40\n",
            "20240/32426 [=================>............] - ETA: 9s - loss: 0.0165 - acc: 0.9921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 29s 880us/step - loss: 0.0169 - acc: 0.9919 - val_loss: 0.1302 - val_acc: 0.9613\n",
            "Epoch 17/40\n",
            "30480/32426 [===========================>..] - ETA: 1s - loss: 0.0159 - acc: 0.9925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 29s 879us/step - loss: 0.0161 - acc: 0.9923 - val_loss: 0.1543 - val_acc: 0.9639\n",
            "Epoch 18/40\n",
            "32426/32426 [==============================] - 28s 873us/step - loss: 0.0165 - acc: 0.9915 - val_loss: 0.2270 - val_acc: 0.9600\n",
            "Epoch 19/40\n",
            " 1200/32426 [>.............................] - ETA: 24s - loss: 0.0157 - acc: 0.9925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 873us/step - loss: 0.0182 - acc: 0.9920 - val_loss: 0.3280 - val_acc: 0.9550\n",
            "Epoch 20/40\n",
            "23440/32426 [====================>.........] - ETA: 7s - loss: 0.0202 - acc: 0.9910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 874us/step - loss: 0.0186 - acc: 0.9915 - val_loss: 0.2500 - val_acc: 0.9606\n",
            "Epoch 21/40\n",
            "31520/32426 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 29s 880us/step - loss: 0.0143 - acc: 0.9921 - val_loss: 0.2353 - val_acc: 0.9608\n",
            "Epoch 22/40\n",
            "32426/32426 [==============================] - 28s 872us/step - loss: 0.0200 - acc: 0.9908 - val_loss: 0.2301 - val_acc: 0.9565\n",
            "Epoch 23/40\n",
            " 1360/32426 [>.............................] - ETA: 24s - loss: 0.0189 - acc: 0.9860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 876us/step - loss: 0.0188 - acc: 0.9908 - val_loss: 0.3512 - val_acc: 0.9497\n",
            "Epoch 24/40\n",
            "23600/32426 [====================>.........] - ETA: 6s - loss: 0.0174 - acc: 0.9914"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 863us/step - loss: 0.0178 - acc: 0.9917 - val_loss: 0.2372 - val_acc: 0.9641\n",
            "Epoch 25/40\n",
            "32240/32426 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9916"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 864us/step - loss: 0.0180 - acc: 0.9916 - val_loss: 0.2056 - val_acc: 0.9662\n",
            "Epoch 26/40\n",
            "32426/32426 [==============================] - 28s 849us/step - loss: 0.0166 - acc: 0.9922 - val_loss: 0.4430 - val_acc: 0.9531\n",
            "Epoch 27/40\n",
            " 1920/32426 [>.............................] - ETA: 23s - loss: 0.0108 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 832us/step - loss: 0.0178 - acc: 0.9915 - val_loss: 0.2821 - val_acc: 0.9492\n",
            "Epoch 28/40\n",
            "24240/32426 [=====================>........] - ETA: 6s - loss: 0.0162 - acc: 0.9918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 832us/step - loss: 0.0165 - acc: 0.9919 - val_loss: 0.4082 - val_acc: 0.9543\n",
            "Epoch 29/40\n",
            "32426/32426 [==============================] - 27s 838us/step - loss: 0.0150 - acc: 0.9925 - val_loss: 0.4719 - val_acc: 0.9483\n",
            "Epoch 30/40\n",
            "   80/32426 [..............................] - ETA: 25s - loss: 3.8818e-07 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 843us/step - loss: 0.0177 - acc: 0.9917 - val_loss: 0.3027 - val_acc: 0.9600\n",
            "Epoch 31/40\n",
            "23520/32426 [====================>.........] - ETA: 6s - loss: 0.0153 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 848us/step - loss: 0.0151 - acc: 0.9926 - val_loss: 0.2597 - val_acc: 0.9650\n",
            "Epoch 32/40\n",
            "32400/32426 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 847us/step - loss: 0.0180 - acc: 0.9923 - val_loss: 0.3314 - val_acc: 0.9541\n",
            "Epoch 33/40\n",
            "32426/32426 [==============================] - 28s 850us/step - loss: 0.0206 - acc: 0.9915 - val_loss: 0.3176 - val_acc: 0.9611\n",
            "Epoch 34/40\n",
            " 1920/32426 [>.............................] - ETA: 23s - loss: 0.0150 - acc: 0.9943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 847us/step - loss: 0.0155 - acc: 0.9922 - val_loss: 0.3157 - val_acc: 0.9590\n",
            "Epoch 35/40\n",
            "24240/32426 [=====================>........] - ETA: 6s - loss: 0.0163 - acc: 0.9917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 846us/step - loss: 0.0170 - acc: 0.9920 - val_loss: 0.9073 - val_acc: 0.9074\n",
            "Epoch 36/40\n",
            "32426/32426 [==============================] - 27s 847us/step - loss: 0.0174 - acc: 0.9921 - val_loss: 0.3039 - val_acc: 0.9664\n",
            "Epoch 37/40\n",
            "   80/32426 [..............................] - ETA: 25s - loss: 0.0066 - acc: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 848us/step - loss: 0.0192 - acc: 0.9919 - val_loss: 0.4288 - val_acc: 0.9564\n",
            "Epoch 38/40\n",
            "23520/32426 [====================>.........] - ETA: 6s - loss: 0.0167 - acc: 0.9917"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 28s 860us/step - loss: 0.0183 - acc: 0.9916 - val_loss: 0.3124 - val_acc: 0.9655\n",
            "Epoch 39/40\n",
            "32160/32426 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32426/32426 [==============================] - 27s 844us/step - loss: 0.0202 - acc: 0.9918 - val_loss: 0.4002 - val_acc: 0.9561\n",
            "Epoch 40/40\n",
            "32426/32426 [==============================] - 27s 836us/step - loss: 0.0223 - acc: 0.9915 - val_loss: 0.4137 - val_acc: 0.9560\n",
            "Test loss: 0.41371132182068915\n",
            "Test accuracy: 0.9559754196092819\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.80      0.98      0.88       164\n",
            "          1       1.00      0.99      1.00       164\n",
            "          2       0.90      1.00      0.95       164\n",
            "          3       0.67      1.00      0.81       161\n",
            "          4       0.89      0.85      0.87       164\n",
            "          5       1.00      0.81      0.90       164\n",
            "          6       1.00      0.72      0.84       164\n",
            "          7       0.94      1.00      0.97       144\n",
            "          8       1.00      1.00      1.00       166\n",
            "          9       1.00      1.00      1.00       164\n",
            "         10       1.00      1.00      1.00       164\n",
            "         11       1.00      1.00      1.00       143\n",
            "         12       1.00      1.00      1.00       166\n",
            "         13       1.00      0.81      0.89       166\n",
            "         14       0.91      0.99      0.95       166\n",
            "         15       0.93      0.98      0.95       166\n",
            "         16       1.00      1.00      1.00       164\n",
            "         17       0.89      1.00      0.94       164\n",
            "         18       0.88      1.00      0.94       166\n",
            "         19       0.64      0.68      0.66       164\n",
            "         20       0.78      0.74      0.76       246\n",
            "         21       1.00      0.91      0.96       246\n",
            "         22       1.00      1.00      1.00       166\n",
            "         23       1.00      0.95      0.98       166\n",
            "         24       0.98      1.00      0.99       166\n",
            "         25       1.00      1.00      1.00       166\n",
            "         26       0.85      1.00      0.92       164\n",
            "         27       1.00      1.00      1.00       166\n",
            "         28       1.00      1.00      1.00       166\n",
            "         29       1.00      1.00      1.00       166\n",
            "         30       1.00      1.00      1.00       164\n",
            "         31       1.00      1.00      1.00       166\n",
            "         32       1.00      1.00      1.00       166\n",
            "         33       1.00      1.00      1.00       166\n",
            "         34       1.00      1.00      1.00       156\n",
            "         35       1.00      1.00      1.00       166\n",
            "         36       1.00      1.00      1.00       164\n",
            "         37       1.00      1.00      1.00       166\n",
            "         38       1.00      1.00      1.00       166\n",
            "         39       1.00      1.00      1.00       166\n",
            "         40       1.00      0.80      0.89       166\n",
            "         41       1.00      1.00      1.00       166\n",
            "         42       1.00      0.78      0.88       166\n",
            "         43       1.00      1.00      1.00       246\n",
            "         44       0.97      0.83      0.89       164\n",
            "         45       1.00      1.00      1.00       160\n",
            "         46       1.00      1.00      1.00       164\n",
            "         47       1.00      1.00      1.00       166\n",
            "         48       1.00      0.99      1.00       164\n",
            "         49       0.97      0.88      0.93       164\n",
            "         50       1.00      0.68      0.81       164\n",
            "         51       1.00      0.89      0.94       166\n",
            "         52       1.00      1.00      1.00       166\n",
            "         53       0.99      1.00      1.00       166\n",
            "         54       1.00      1.00      1.00       166\n",
            "         55       0.98      1.00      0.99       166\n",
            "         56       0.90      1.00      0.95       166\n",
            "         57       1.00      1.00      1.00       151\n",
            "         58       0.86      1.00      0.92       164\n",
            "         59       1.00      1.00      1.00       166\n",
            "         60       1.00      1.00      1.00       166\n",
            "         61       0.98      1.00      0.99       162\n",
            "         62       1.00      1.00      1.00       164\n",
            "         63       1.00      1.00      1.00       166\n",
            "         64       0.83      1.00      0.91       166\n",
            "\n",
            "avg / total       0.96      0.96      0.96     10903\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wQc3lRHSR2YH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#tại epochs = 14 đạt giá trị val_acc = 0.97 cao nhất: load model tại epoch = 27:\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZS0tgIcJzm5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "377c2890-09a8-4a85-ce83-635787aedde2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529740179771,
          "user_tz": -420,
          "elapsed": 2225,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data2\t\t\t\t   weights.01-0.36.hdf5  weights.07-0.18.hdf5\r\n",
            "datalab\t\t\t\t   weights.02-0.19.hdf5  weights.08-0.14.hdf5\r\n",
            "fruits-360_dataset_2018_06_03.zip  weights.03-0.17.hdf5  weights.10-0.15.hdf5\r\n",
            "models\t\t\t\t   weights.04-0.17.hdf5  weights.14-0.11.hdf5\r\n",
            "store\t\t\t\t   weights.05-0.18.hdf5\r\n",
            "weights.01-0.32.hdf5\t\t   weights.06-0.19.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iN_UTsINoJMX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1193
        },
        "outputId": "3ae00843-46ee-4f1e-f083-88ed031c6aab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529740381622,
          "user_tz": -420,
          "elapsed": 7308,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "modelbest = keras.models.load_model('weights.14-0.11.hdf5')\n",
        "from sklearn.metrics import classification_report\n",
        "classes = modelbest.predict_classes(x_test, batch_size = None)\n",
        "print(classification_report(validation_label_id, classes))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.80      0.84      0.82       164\n",
            "          1       1.00      0.99      1.00       164\n",
            "          2       1.00      1.00      1.00       164\n",
            "          3       0.80      0.99      0.88       161\n",
            "          4       0.99      0.96      0.98       164\n",
            "          5       1.00      0.99      1.00       164\n",
            "          6       1.00      0.88      0.94       164\n",
            "          7       1.00      1.00      1.00       144\n",
            "          8       1.00      1.00      1.00       166\n",
            "          9       1.00      1.00      1.00       164\n",
            "         10       1.00      1.00      1.00       164\n",
            "         11       1.00      1.00      1.00       143\n",
            "         12       0.99      1.00      0.99       166\n",
            "         13       1.00      0.93      0.96       166\n",
            "         14       0.93      0.95      0.94       166\n",
            "         15       0.95      1.00      0.97       166\n",
            "         16       1.00      1.00      1.00       164\n",
            "         17       0.83      0.99      0.90       164\n",
            "         18       1.00      1.00      1.00       166\n",
            "         19       0.62      0.67      0.65       164\n",
            "         20       0.77      0.73      0.75       246\n",
            "         21       1.00      0.86      0.93       246\n",
            "         22       1.00      1.00      1.00       166\n",
            "         23       1.00      0.95      0.98       166\n",
            "         24       1.00      1.00      1.00       166\n",
            "         25       1.00      1.00      1.00       166\n",
            "         26       1.00      1.00      1.00       164\n",
            "         27       0.99      1.00      1.00       166\n",
            "         28       1.00      1.00      1.00       166\n",
            "         29       1.00      1.00      1.00       166\n",
            "         30       1.00      1.00      1.00       164\n",
            "         31       1.00      1.00      1.00       166\n",
            "         32       1.00      1.00      1.00       166\n",
            "         33       1.00      1.00      1.00       166\n",
            "         34       1.00      1.00      1.00       156\n",
            "         35       1.00      1.00      1.00       166\n",
            "         36       1.00      1.00      1.00       164\n",
            "         37       1.00      1.00      1.00       166\n",
            "         38       1.00      1.00      1.00       166\n",
            "         39       1.00      1.00      1.00       166\n",
            "         40       1.00      0.91      0.95       166\n",
            "         41       1.00      1.00      1.00       166\n",
            "         42       0.99      1.00      0.99       166\n",
            "         43       1.00      0.99      1.00       246\n",
            "         44       0.85      0.91      0.88       164\n",
            "         45       1.00      1.00      1.00       160\n",
            "         46       1.00      1.00      1.00       164\n",
            "         47       1.00      1.00      1.00       166\n",
            "         48       1.00      1.00      1.00       164\n",
            "         49       1.00      1.00      1.00       164\n",
            "         50       1.00      0.79      0.88       164\n",
            "         51       0.93      0.93      0.93       166\n",
            "         52       1.00      1.00      1.00       166\n",
            "         53       0.99      1.00      1.00       166\n",
            "         54       1.00      1.00      1.00       166\n",
            "         55       1.00      1.00      1.00       166\n",
            "         56       1.00      1.00      1.00       166\n",
            "         57       1.00      1.00      1.00       151\n",
            "         58       1.00      1.00      1.00       164\n",
            "         59       1.00      0.99      0.99       166\n",
            "         60       1.00      1.00      1.00       166\n",
            "         61       0.95      1.00      0.98       162\n",
            "         62       1.00      1.00      1.00       164\n",
            "         63       1.00      1.00      1.00       166\n",
            "         64       0.92      1.00      0.96       166\n",
            "\n",
            "avg / total       0.97      0.97      0.97     10903\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "insD6QFcpHb3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "06089312-9520-40bf-c1d4-25bd83a398a1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529740748928,
          "user_tz": -420,
          "elapsed": 691,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "modelbest.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_53 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 26, 26, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 256)               2769152   \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 65)                16705     \n",
            "=================================================================\n",
            "Total params: 2,842,209\n",
            "Trainable params: 2,842,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rjiAXn8vI_u",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1210
        },
        "outputId": "61f0642e-4b68-49b7-933c-e88521480bc4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529651292693,
          "user_tz": -420,
          "elapsed": 221129,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# sử dụng randomforest để phân loại\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(training_fruit_img.reshape(training_fruit_img.shape[0],64*64*3), training_label_id)\n",
        "pred = rf.predict(validation_fruit_img.reshape(validation_fruit_img.shape[0],64*64*3))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred))\n",
        "print(np.sum(y_test==pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.76      0.71      0.74       164\n",
            "          1       0.77      0.94      0.85       164\n",
            "          2       0.94      1.00      0.97       164\n",
            "          3       1.00      1.00      1.00       161\n",
            "          4       1.00      1.00      1.00       164\n",
            "          5       1.00      1.00      1.00       164\n",
            "          6       0.93      1.00      0.96       164\n",
            "          7       1.00      1.00      1.00       144\n",
            "          8       1.00      1.00      1.00       166\n",
            "          9       0.99      0.76      0.86       164\n",
            "         10       1.00      1.00      1.00       164\n",
            "         11       1.00      0.88      0.94       143\n",
            "         12       1.00      1.00      1.00       166\n",
            "         13       0.99      0.80      0.88       166\n",
            "         14       0.80      0.84      0.82       166\n",
            "         15       0.97      0.90      0.94       166\n",
            "         16       0.99      1.00      1.00       164\n",
            "         17       0.97      0.99      0.98       164\n",
            "         18       0.99      1.00      1.00       166\n",
            "         19       0.65      0.69      0.67       164\n",
            "         20       0.78      0.75      0.77       246\n",
            "         21       1.00      1.00      1.00       246\n",
            "         22       1.00      1.00      1.00       166\n",
            "         23       1.00      0.95      0.98       166\n",
            "         24       0.88      1.00      0.94       166\n",
            "         25       0.98      1.00      0.99       166\n",
            "         26       0.81      1.00      0.89       164\n",
            "         27       1.00      1.00      1.00       166\n",
            "         28       1.00      1.00      1.00       166\n",
            "         29       1.00      1.00      1.00       166\n",
            "         30       1.00      1.00      1.00       164\n",
            "         31       0.98      1.00      0.99       166\n",
            "         32       1.00      1.00      1.00       166\n",
            "         33       0.97      1.00      0.99       166\n",
            "         34       1.00      1.00      1.00       156\n",
            "         35       1.00      0.98      0.99       166\n",
            "         36       1.00      1.00      1.00       164\n",
            "         37       1.00      1.00      1.00       166\n",
            "         38       1.00      1.00      1.00       166\n",
            "         39       1.00      1.00      1.00       166\n",
            "         40       0.95      1.00      0.98       166\n",
            "         41       1.00      1.00      1.00       166\n",
            "         42       0.99      0.83      0.90       166\n",
            "         43       1.00      1.00      1.00       246\n",
            "         44       0.79      0.77      0.78       164\n",
            "         45       1.00      1.00      1.00       160\n",
            "         46       1.00      1.00      1.00       164\n",
            "         47       1.00      1.00      1.00       166\n",
            "         48       1.00      0.76      0.87       164\n",
            "         49       0.97      0.85      0.90       164\n",
            "         50       1.00      1.00      1.00       164\n",
            "         51       0.81      0.84      0.83       166\n",
            "         52       0.97      1.00      0.99       166\n",
            "         53       1.00      1.00      1.00       166\n",
            "         54       1.00      0.97      0.98       166\n",
            "         55       1.00      1.00      1.00       166\n",
            "         56       0.79      0.99      0.88       166\n",
            "         57       0.90      1.00      0.95       151\n",
            "         58       1.00      1.00      1.00       164\n",
            "         59       1.00      1.00      1.00       166\n",
            "         60       1.00      1.00      1.00       166\n",
            "         61       0.94      1.00      0.97       162\n",
            "         62       1.00      0.87      0.93       164\n",
            "         63       1.00      1.00      1.00       166\n",
            "         64       1.00      1.00      1.00       166\n",
            "\n",
            "avg / total       0.96      0.95      0.95     10903\n",
            "\n",
            "10406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ElaYGXHRB6s5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model dùng randomforest cho kết quả khá giống với cnn mặc dù accurancy thấp hơn."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LznfoHZsaA7c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hxl9924z5IVY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d2ed0343-3088-4536-ff7f-a2cfd97a8369",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529651315733,
          "user_tz": -420,
          "elapsed": 2226,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple.jpg\t\t\t     lemon1.jpg  thahlongtest.jpg\r\n",
            "data2\t\t\t\t     lemon.jpg\t tmp\r\n",
            "datalab\t\t\t\t     logs\t vai.jpg\r\n",
            "fruits-360_dataset_2018_06_03.zip    logs2\r\n",
            "fruits-360_dataset_2018_06_03.zip.1  logs2.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5OW13nTE2jWH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e2ea951f-0ea7-425a-f729-1643b62688f1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529651316504,
          "user_tz": -420,
          "elapsed": 692,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EIOYNnqX59U2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "10ca549c-0781-4c6e-9432-7ba1abaeef3d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529651317563,
          "user_tz": -420,
          "elapsed": 619,
          "user": {
            "displayName": "Phạm Khánh",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "108013420442388490411"
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}